{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ac7ddf-56f6-471b-ab3d-e92ea423b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values in a dataset refer to the absence of data in one or more features for some observations.\n",
    "# Handling missing values is important because they can affect the performance and accuracy of machine learning models. Missing values can result in biased and \n",
    "# inconsistent estimates of parameters, \n",
    "# which can lead to incorrect predictions or decisions.\n",
    "# Some algorithms that are not affected by missing values are tree-based models like Random Forest, Decision Trees, and XGBoost, and some distance-based algorithms like K-Nearest\n",
    "# Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7a1ed7-b6ae-4625-9ad7-682aa31ccc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping missing values\n",
    "# Mean/median imputation\n",
    "# Mode imputation\n",
    "# Regression imputation\n",
    "# Multiple imputation\n",
    "\n",
    "# df.dropna(inplace=True)\n",
    "\n",
    "# df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# df.fillna(df.mode().iloc[0], inplace=True)\n",
    "\n",
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import IterativeImputer\n",
    "# imp = IterativeImputer()\n",
    "# df_imputed = imp.fit_transform(df)\n",
    "\n",
    "# from sklearn.impute import IterativeImputer\n",
    "# from sklearn.experimental import enable_iterative_imputer\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# imp = IterativeImputer(RandomForestRegressor())\n",
    "# imp_mean = SimpleImputer(strategy='mean')\n",
    "# steps = [('imputation', imp), ('mean_imputation', imp_mean)]\n",
    "# pipeline = Pipeline(steps)\n",
    "# df_imputed = pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07aacbe1-b4c6-4e76-b0a0-f416f770be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced data is a situation in which the number of observations in one class is significantly larger or smaller than the number of observations in the other class.\n",
    "# If imbalanced data is not handled, the machine learning model will tend to predict the majority class, ignoring the minority class. This will lead to biased and inaccurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8455755f-ad07-4a27-865f-551f553887cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up-sampling is a technique used to balance an imbalanced dataset by increasing the number of samples in the minority class. \n",
    "# Down-sampling is a technique used to balance an imbalanced dataset by decreasing the number of samples in the majority class.\n",
    "# For example, if we have a dataset with 100 observations, out of which 10 belong to the minority class and 90 belong to the majority class, \n",
    "# we can up-sample the minority class by replicating the 10 observations multiple times to make the number of samples equal to the majority class. \n",
    "# We can down-sample the majority class by randomly selecting 10 observations from the majority class to make the number of samples equal to the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3960b293-e36f-4839-ab59-bd9ecb728419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation is a technique used to generate additional training data by applying various transformations to the existing data. \n",
    "# SMOTE (Synthetic Minority Over-sampling Technique) is a data augmentation technique used to balance an imbalanced dataset by generating synthetic samples of the minority class.\n",
    "# SMOTE selects two or more similar minority class observations and creates a new observation at a point along the line joining these similar observations.\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# smote = SMOTE()\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855b02e4-eaf0-4c13-b742-bc78127c5578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers are observations in a dataset that are significantly different from other observations. These are data points that lie far away from the bulk of the data points \n",
    "# and can affect the overall statistical analysis and modeling of a dataset. Outliers can be caused due to errors in data collection or entry, unusual events or behaviors\n",
    "# , or simply natural variations in the data.\n",
    "\n",
    "# It is essential to handle outliers because they can distort the statistical analyses of a dataset and can cause errors in the modeling process. \n",
    "# Outliers can also have a significant impact on the results of machine learning algorithms and can cause overfitting or underfitting. Moreover, \n",
    "# outliers can skew the mean and standard deviation, leading to misleading conclusions about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc023bce-77d1-4e7d-94df-d563fb819c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the rows or columns with missing data if they do not have a significant impact on the analysis\n",
    "# Imputing the missing data with a value such as the mean or median of the available data\n",
    "# Using machine learning algorithms to predict missing values based on the available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4a02254-dfb6-4418-b163-7cb5f3a8fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the relationship between missing data and other variables in the dataset\n",
    "# Using statistical tests to determine if the missing data is related to other variables in the dataset\n",
    "# Creating a missing data indicator variable to account for the missing data in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9be41b4-f1e4-43a5-87ee-047f62c06c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using evaluation metrics that are suitable for imbalanced datasets such as precision, recall, F1-score, and AUC-ROC\n",
    "# Adjusting the classification threshold to balance the precision and recall of the model\n",
    "# Using techniques such as oversampling or undersampling to balance the classes in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4cf2a9-9a41-49b2-b98c-826801b5ec68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
