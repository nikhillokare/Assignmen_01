{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd76a0c-b784-4907-bc53-993459b08ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Simple linear regression is a statistical method that models the linear relationship between a dependent variable and a single independent variable. On the other hand, multiple linear regression is a statistical method that models the linear relationship between a dependent variable and two or more independent variables.\n",
    "\n",
    "# Example of Simple Linear Regression:\n",
    "# Suppose we want to predict a student's score on a test based on the number of hours they studied. Here, we have only one independent variable (hours studied) and one dependent variable (test score). Hence, this is an example of simple linear regression.\n",
    "\n",
    "# Example of Multiple Linear Regression:\n",
    "# Suppose we want to predict a house's price based on its size, number of bedrooms, and location. Here, we have three independent variables (size, number of bedrooms, and location) and one dependent variable (house price). Hence, this is an example of multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd2739b-05d8-4253-bd43-7a27ace7818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. The assumptions of linear regression are:\n",
    "\n",
    "# Linearity: There should be a linear relationship between the independent and dependent variables.\n",
    "# Independence: The observations should be independent of each other.\n",
    "# Homoscedasticity: The variance of the errors should be constant across all levels of the independent variables.\n",
    "# Normality: The errors should be normally distributed with a mean of 0.\n",
    "# No multicollinearity: The independent variables should not be highly correlated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0792f4-b7db-4dcf-8796-f921798ad2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. In a linear regression model, the slope represents the change in the dependent variable for a unit change in the independent variable. The intercept represents the value of the dependent variable when the independent variable is zero.\n",
    "\n",
    "# Example: Suppose we want to predict a person's salary based on their years of experience. The slope of the linear regression model represents how much salary increases for each additional year of experience. The intercept represents the predicted salary for someone with zero years of experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28d04aa8-e303-4ce5-a64b-e618e4d87293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Gradient descent is an optimization algorithm used in machine learning to minimize the loss function of a model. It works by iteratively adjusting the model's parameters in the direction of steepest descent of the loss function until convergence.\n",
    "\n",
    "# In machine learning, gradient descent is used to update the weights of the model during training. It calculates the gradient of the loss function with respect to the weights and adjusts the weights in the opposite direction of the gradient to minimize the los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0257f252-6f17-4bfc-8dbc-82d26769002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Multiple linear regression is a statistical method that models the linear relationship between a dependent variable and two or more independent variables. It differs from simple linear regression in that it allows for more than one independent variable.\n",
    "\n",
    "# The multiple linear regression model can be represented as:\n",
    "# Y = b0 + b1X1 + b2X2 + ... + bn*Xn + e\n",
    "# where Y is the dependent variable, X1, X2, ..., Xn are the independent variables, b0 is the intercept, and b1, b2, ..., bn are the coefficients of the independent variables. e is the error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc228a1-726c-489f-91b8-b11484a679e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Multicollinearity is a phenomenon that occurs when two or more independent variables in a multiple linear regression model are highly correlated with each other. This can cause problems in the model, such as unstable coefficients and inflated standard errors.\n",
    "\n",
    "# To detect multicollinearity, we can use diagnostic plots like scatterplots and correlation matrices. We can also use statistical tests like the variance inflation factor (VIF) to quantify the extent of multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0c0e172-9734-423c-a0fd-4288abae4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Polynomial regression is a type of regression analysis that models the relationship between the dependent variable and independent variable(s) as an nth degree polynomial function. Unlike linear regression, which assumes a linear relationship between the variables, polynomial regression can capture non-linear relationships between the variables.\n",
    "\n",
    "# The polynomial regression model can be represented as:\n",
    "# Y = b0 + b1X + b2X^2 + ... + bn*X^n + e\n",
    "# where Y is the dependent variable, X is the independent variable, b0, b1, b2, ..., bn are the coefficients of the polynomial terms, n is the degree of the polynomial, and e is the error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12d2c2-798f-4781-b79a-7eca15c80780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. Advantages of polynomial regression include its ability to model non-linear relationships between the variables, its flexibility in choosing the degree of the polynomial, and its ability to fit complex data patterns.\n",
    "\n",
    "# Disadvantages of polynomial regression include overfitting to the training data, which can lead to poor generalization to new data, and the difficulty in interpreting the model coefficients.\n",
    "\n",
    "# Polynomial regression is useful in situations where the relationship between the variables is non-linear and cannot be captured by a linear model. However, it should be used with caution and the degree of the polynomial should be chosen based on the data and the problem at hand. In general, simpler models should be preferred over more complex models to avoid overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
